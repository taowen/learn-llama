# learn-llama

llama+gptq has multiple open source impelementations. This makes learning how to re-implement llama+gptq on other programming api much easier.

## tokenizer
* https://github.com/google/sentencepiece

## llama model
* https://github.com/facebookresearch/llama
* https://github.com/ggerganov/llama.cpp
* https://github.com/turboderp/exllama
* https://github.com/Lightning-AI/lit-llama
* https://github.com/huggingface/transformers/tree/main/src/transformers/models/llama
* https://github.com/marella/ctransformers/blob/main/models/llms/llama.cc
* https://github.com/OpenNMT/CTranslate2/blob/master/python/ctranslate2/converters/transformers.py
* https://github.com/kayvr/token-hawk

## gptq quantization
* https://github.com/IST-DASLab/gptq
* https://github.com/turboderp/exllama
* https://github.com/qwopqwop200/GPTQ-for-LLaMa
* https://github.com/PanQiWei/AutoGPTQ
* https://github.com/fpgaminer/GPTQ-triton
* https://github.com/Lightning-AI/lit-llama/blob/main/lit_llama/quantization.py
* https://github.com/mlc-ai/mlc-llm/blob/main/mlc_llm/quantization/autogptq_quantization.py
* https://github.com/LeiWang1999/AutoGPTQ.tvm
