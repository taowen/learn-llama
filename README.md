# learn-llama

llama+gptq has multiple open source impelementations. This makes learning how to re-implement llama+gptq on other programming api much easier.

## llama model
* https://github.com/facebookresearch/llama
* https://github.com/ggerganov/llama.cpp
* https://github.com/turboderp/exllama
* https://github.com/Lightning-AI/lit-llama
* https://github.com/huggingface/transformers/tree/main/src/transformers/models/llama

## gptq quantization
* https://github.com/IST-DASLab/gptq
* https://github.com/turboderp/exllama
* https://github.com/qwopqwop200/GPTQ-for-LLaMa
* https://github.com/PanQiWei/AutoGPTQ
* https://github.com/fpgaminer/GPTQ-triton
* https://github.com/Lightning-AI/lit-llama/blob/main/lit_llama/quantization.py
* https://github.com/mlc-ai/mlc-llm/blob/main/mlc_llm/quantization/autogptq_quantization.py
